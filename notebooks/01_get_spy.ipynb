{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stark Broadening Asymmetries From SPY\n",
    "\n",
    "[The SPY survey](https://ui.adsabs.harvard.edu/abs/2020A%26A...638A.131N/abstract) has a ton of high-res WD spectra. I'm gonna see how much Stark broadening affects their absorption lines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "from astropy.io import ascii\n",
    "from astropy.table import Table, join\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('../../../proj/core-composition/notebooks/stefan.mplstyle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not find the pickled WD models. If you need to use these models, please re-import corv with the proper path.\n",
      "/Users/vedantchandra/0_research/01_sdss5/006_build_corv/data/comm_cat/\n",
      "star and exposure catalogs not found! check paths and run make_catalogs() if you want to use sdss functionality. otherwise ignore.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "from stark import spy\n",
    "from stark import measure as meas\n",
    "\n",
    "# read in the object file from CDS\n",
    "obj = spy.fetch_objfile()\n",
    "\n",
    "## Uncomment to run only the SDSS WDs\n",
    "#sdss_wds = Table.read('./data/raw/25SDSS_inSPY.csv')\n",
    "#sdss_wds.remove_columns(['ra', 'dec'])\n",
    "#cat = join(cat, sdss_wds, keys_left='Name', keys_right='Name_2', join_type='inner')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit Four Balmer Lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1391 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "sp = spy.SPYHandler(obj)\n",
    "abgd_result = sp.analyze_table('../data/processed/spy/all_wds_Habgd.json', lines = ['a','b','g','d'], from_cache=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('../data/processed/spy/all_wds_Habgd.json') as json_file:\n",
    "    abgd_result = json.load(json_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit Two Balmer Lines\n",
    "\n",
    "The raw spectra downloaded directly off of the CDS archive lives at `./data/raw/sp/`. These spectra are in air wavelengths, and their radial velocities are reported in the heliocentric frame. That means that we need to convert to vacuum wavelengths and determine the heliocentric correction. Doing this for all the files takes a while. I'm going to pre-compute it soon, but I haven't gotten there yet. \n",
    "\n",
    "The `spec` variable is a dictionary whose keys are filenames and whose data are the associated wavelengths. The `obj` variable is a table containing all the information from the CDS archive, as well as the heliocentric correction. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp = spy.SPYHandler(obj)\n",
    "ab_result = sp.analyze_table('../data/processed/spy/all_wds_Hab.json', lines = ['a','b'], from_cache=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('../data/processed/spy/all_wds_Hab.json') as json_file:\n",
    "    ab_result = json.load(json_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the line that does the actual analysis. The parameter `from_cache=True` means that you can stop the calculation and start it at another time using the data contained in the file it's pointing to. If you want to just look at the results, you can comment out the `analyze_spectra()` line and uncomment the json read line."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This cell converts the json file into a pandas dataframe, then calculates a mask based on the parameters specified in the `apply_rules()` function. After that, it fills in any masked values with `NaN` so that they'll be ignored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = ct.tabularize(measured)\n",
    "df_with_mask = ct.apply_rules(df, sigma = 3 , rv_over_err = 3, chisqr = 10)\n",
    "df_masked = ct.apply_mask(df_with_mask, rows = ['rvs', 'e_rvs', 'differentials', 'significance', \n",
    "                                             'redchisqr', 'teff', 'e_teff', 'logg', 'e_logg'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stark import utils\n",
    "\n",
    "temp_bin_edges = [0, 13000, 16000]\n",
    "df_binned, range_func, center_func = utils.bin_temperatures(df_masked, temp_bin_edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for edge in np.unique(df.teff_bin):\n",
    "    print(f\"{edge} | {range_func(edge)} | # objects = {(df['teff_bin'] == edge).sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_ensemble(df):\n",
    "    fig, ax = plt.subplots(nrows = 1, figsize=(10,6))\n",
    "\n",
    "    colors = {1 : 'red', 3 : 'blue'}\n",
    "    for edge in np.unique(df.teff_bin)[::2]:\n",
    "        subset = df.query(f\"teff_bin == {edge}\")\n",
    "        diffs = np.array(subset.differentials.tolist(), dtype=float)\n",
    "        wl = np.array(subset.windows.tolist())[0,1:]\n",
    "\n",
    "        avg_rows = (np.count_nonzero(~np.isnan(diffs)) // 10)\n",
    "        mean_diff = np.nanmean(diffs[:,1:], axis=0)\n",
    "        median_diff = np.nanmedian(diffs[:,1:], axis=0)\n",
    "        std_diff = np.nanstd(diffs[:,1:], axis=0)\n",
    "\n",
    "        scatter = {'s' : 40}\n",
    "        low, hi = range_func(edge)\n",
    "        ax.scatter(wl, median_diff, label = f'{low} < Teff <= {hi} (n = {len(subset)})', color = colors[edge], s = 60, zorder=10)\n",
    "\n",
    "    diffs = np.array(df.differentials.tolist(), dtype=float)\n",
    "    wl = np.array(df.windows.tolist())[0,1:]\n",
    "\n",
    "    avg_rows = (np.count_nonzero(~np.isnan(diffs)) // 10)\n",
    "    mean_diff = np.nanmean(diffs[:,1:], axis=0)\n",
    "    median_diff = np.nanmedian(diffs[:,1:], axis=0)\n",
    "    std_diff = np.nanstd(diffs[:,1:], axis=0)\n",
    "\n",
    "    scatter = {'s' : 40}\n",
    "    low, hi = range_func(edge)\n",
    "    ax.scatter(wl, median_diff, label = f'All Points', color = 'k', s = 60, zorder=10)\n",
    "\n",
    "    xmin, xmax = ax.get_xlim()\n",
    "    #ax.fill_between([xmin,xmax], -ref_e_rv, ref_e_rv, color='green', alpha=0.5, zorder=0)\n",
    "    ax.set_xlim(xmin, xmax)\n",
    "    ax.axhline(y = 0, c = 'k', ls = '--')\n",
    "\n",
    "    hfont = {'fontname':'Helvetica'}\n",
    "    ax.set_ylim(-10,10)   \n",
    "    ax.set_xlabel(r'Fit Window Size [$\\AA$]')\n",
    "    ax.set_ylabel('$RV_{Wing} - RV_{NLTE}$ \\n$[km /s]$')\n",
    "    ax.legend()\n",
    "\n",
    "plot_ensemble(df_masked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stark",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
